{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1509e1-4475-4ac6-9584-fe467481cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def find_file_upwards(filename, start_path='.'):\n",
    "    current_path = Path(start_path).resolve()\n",
    "\n",
    "    for parent in [current_path] + list(current_path.parents):\n",
    "        if (parent / filename).exists():\n",
    "            return parent\n",
    "    return None\n",
    "\n",
    "ROOT_PATH = find_file_upwards(\"pyproject.toml\")\n",
    "sys.path.append(str(ROOT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad25a3b2-9b9e-425f-9744-aa93f292fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cahos import Scale, scale_schema, VoiceLeading, voice_leading_schema, get_scales, make_scale, make_voice_leading, \\\n",
    "    Instruments, mark_changes, get_swaps, get_span, get_n_pseudo_changes, count_upward_motion, count_downward_motion, midis_to_names, \\\n",
    "    calculate_entropy, calculate_sequence_entropy, calculate_motion_balance, get_max_step_size, IntSequence12\n",
    "import polars as pl\n",
    "import mido\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "from operator import ge, le, and_, or_, eq\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from functools import reduce, partial\n",
    "import random\n",
    "from itertools import product, permutations\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79ee50-cd4d-487f-b404-459d62dc52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(ROOT_PATH).joinpath(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26565d-14f4-4d73-b9bd-621668bc8db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = [\n",
    "    Instruments.flute,\n",
    "    Instruments.oboe,\n",
    "    Instruments.clarinet,\n",
    "    Instruments.bassoon,\n",
    "    Instruments.horn,\n",
    "    Instruments.horn,\n",
    "    Instruments.trumpet,\n",
    "    Instruments.violin,\n",
    "    Instruments.violin,\n",
    "    Instruments.viola,\n",
    "    Instruments.cello,\n",
    "    Instruments.contrabass\n",
    "]\n",
    "ensemble.sort(key=lambda inst: inst.register[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc99c7d-85ef-4ce0-b421-5d329844840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = data_dir / \"base_chords.parquet\"\n",
    "\n",
    "load_saved = True\n",
    "if load_saved and saved_path.exists():\n",
    "    base_chords = pl.read_parquet(saved_path)\n",
    "else:\n",
    "    max_span = 69\n",
    "    allowed_intervals = [1, 2, 3, 4, 5, 6, 7]\n",
    "    disallowed_beginnings = []\n",
    "    disallowed_subsequences = [\n",
    "        [1, 2], [2, 1], [3, 1], [1, 3],\n",
    "        # [3, 4], [4, 3],\n",
    "        # [6, 1], [1, 6], [5, 1], [1, 5],\n",
    "        [1, 1], [2, 2],  # [3, 3], [4, 4],\n",
    "        # [5, 5, 5], [6, 6, 6], [7, 7, 7]\n",
    "    ]\n",
    "    \n",
    "    base_chords = pl.DataFrame(\n",
    "        data=(s for s in get_scales(\n",
    "            allowed_intervals=allowed_intervals,\n",
    "            disallowed_subsequences=disallowed_subsequences,\n",
    "            disallowed_beginnings=disallowed_beginnings,\n",
    "            max_span=max_span)\n",
    "        ),\n",
    "        schema=scale_schema\n",
    "    )\n",
    "    \n",
    "    base_chords.write_parquet(saved_path, compression=\"zstd\")\n",
    "\n",
    "print(len(base_chords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272d80a-249f-4226-8807-bba6d87b8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_chords = base_chords.filter(\n",
    "    pl.col(\"n_unique_intervals\") <= 3,\n",
    "    # pl.col(\"span\") >= 48,\n",
    "    # pl.col(\"entropy\") >= 1.5,\n",
    "    # pl.col(\"sequence_entropy\") >= 22.0\n",
    ").sort([\"sequence_entropy\", \"entropy\", \"span\"], descending=True)\n",
    "\n",
    "print(len(selected_chords))\n",
    "selected_chords.unique(subset=[\"interval_set\"], maintain_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76192fc0-ac3c-4d5d-af55-2a73f9093050",
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = np.cumsum(np.vstack(selected_chords[\"intervals\"].to_numpy()), axis=1, dtype=int)\n",
    "reals = np.hstack([\n",
    "    np.zeros((reals.shape[0], 1), dtype=reals.dtype),\n",
    "    reals\n",
    "])\n",
    "\n",
    "offsets = np.arange(*ensemble[0].register)\n",
    "reals = reals[:, :, None] + offsets\n",
    "reals = reals.transpose(0, 2, 1)\n",
    "reals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015414d-4c5b-4bb4-8d2b-53f7503e83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "do_append = True\n",
    "for i, chord_type in enumerate(reals):\n",
    "    for j, based_chord in enumerate(chord_type):\n",
    "        for idx, instrument in enumerate(ensemble):\n",
    "            if based_chord[idx] < instrument.register[0] or based_chord[idx] > instrument.register[1]:\n",
    "                do_append = False\n",
    "                break\n",
    "        if do_append:\n",
    "            indices.append([i, j])\n",
    "        do_append = True\n",
    "\n",
    "indexing = np.array(indices)\n",
    "selected = reals[indexing[:, 0], indexing[:, 1]]\n",
    "selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7653663a-0ede-4c16-859b-b9dc2f8e855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmin(selected[:, -1])\n",
    "idx, selected[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef95dbe-2809-46cc-9b8f-a6bdf64a9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected[(selected[:, 0] == 31) & (selected[:, -1] == 64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee57bda-f3fe-442b-b605-c9a52e29fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroed = selected - selected[:, :1]\n",
    "jdx = np.argmin(zeroed[:, -1])\n",
    "jdx, selected[jdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826bfb69-be6e-4939-aa97-001f09665379",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected[(selected[:, 0] == 34) & (selected[:, -1] == 65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1142c9-b5cf-4283-aaa2-611f7f781ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_make_voice_leading(\n",
    "    midis_a: IntSequence12, midis_b: IntSequence12\n",
    ") -> VoiceLeading:\n",
    "    intervals_a = list(np.diff(midis_a))\n",
    "    intervals_b = list(np.diff(midis_b))\n",
    "    midis_a, midis_b = list(midis_a), list(midis_b)\n",
    "    base_a = midis_a[0]\n",
    "    base_b = midis_b[0]\n",
    "    changes = mark_changes(midis_a, midis_b)\n",
    "    common_notes = [a for a, b in zip(midis_a, midis_b) if a == b]\n",
    "    changed_notes = [(a, b) for a, b in zip(midis_a, midis_b) if a != b]\n",
    "    swaps = get_swaps(midis_a, midis_b)\n",
    "    change_in_span = get_span(midis_b) - get_span(midis_a)\n",
    "    n_upward_motion = count_upward_motion(changed_notes)\n",
    "    n_downward_motion = count_downward_motion(changed_notes)\n",
    "\n",
    "    return VoiceLeading(\n",
    "        intervals_a=intervals_a,\n",
    "        intervals_b=intervals_b,\n",
    "        base_a=base_a,\n",
    "        base_b=base_b,\n",
    "        midis_a=midis_a,\n",
    "        midis_b=midis_b,\n",
    "        note_names_a=midis_to_names(midis_a),\n",
    "        note_names_b=midis_to_names(midis_b),\n",
    "        onehot_changed_voices=changes,\n",
    "        entropy_of_changes=calculate_entropy(changes),\n",
    "        sequence_entropy_of_changes=calculate_sequence_entropy(changes),\n",
    "        common_notes=common_notes,\n",
    "        changed_notes=changed_notes,\n",
    "        swaps=swaps,\n",
    "        n_changed_notes=len(changed_notes),\n",
    "        n_common_notes=len(common_notes),\n",
    "        n_swaps=len(swaps),\n",
    "        change_in_span=change_in_span,\n",
    "        n_upward_motion=n_upward_motion,\n",
    "        n_downward_motion=n_downward_motion,\n",
    "        motion_balance=calculate_motion_balance(n_upward_motion, n_downward_motion),\n",
    "        max_step_size=get_max_step_size(changed_notes),\n",
    "        n_pseudo_changes=get_n_pseudo_changes(midis_a, changed_notes),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c49d8-8eb4-41f4-b071-df96390c27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f60adc8-d1d3-4027-8e63-f1dacfc77367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs_from_bass(a, b, preds, instrument=0):\n",
    "    # Preapare random indices for shuffled iteration\n",
    "    first = selected[(selected[:, instrument] == a) & (selected[:, -1] == 64)].copy()\n",
    "    if b is not None:\n",
    "        second = selected[selected[:, instrument] == b].copy()\n",
    "    else:\n",
    "        second = selected.copy()\n",
    "    \n",
    "    xs = np.arange(first.shape[0])\n",
    "    rng.shuffle(xs)\n",
    "    \n",
    "    ys = np.arange(second.shape[0])\n",
    "    rng.shuffle(ys)\n",
    "    \n",
    "    # loop through pairs\n",
    "    for i in xs:\n",
    "        for j in ys:\n",
    "            # chord must change\n",
    "            if np.all(first[i] == second[j]):\n",
    "                continue\n",
    "    \n",
    "            vl = new_make_voice_leading(first[i], second[j])\n",
    "            # return if all predicates are satisfied\n",
    "            if reduce(and_, (func(vl) for func in preds), True):\n",
    "                return vl\n",
    "\n",
    "def get_pair_with_fixed_first(first, b, preds, instrument=0):\n",
    "    if b is not None:\n",
    "        second = selected[selected[:, instrument] == b].copy()\n",
    "    else:\n",
    "        second = selected.copy()\n",
    "    ys = np.arange(second.shape[0])\n",
    "    rng.shuffle(ys)\n",
    "\n",
    "    for j in ys:\n",
    "        # chord must change\n",
    "        if np.all(first == second[j]):\n",
    "            continue\n",
    "\n",
    "        vl = new_make_voice_leading(first, second[j])\n",
    "        # return if all predicates are satisfied\n",
    "        if reduce(and_, (func(vl) for func in preds), True):\n",
    "            return vl\n",
    "\n",
    "\n",
    "def get_progression_from_bass_line(midis, preds, instrument=0):\n",
    "    chord_pairs = []\n",
    "    for idx in range(len(midis) - 1):\n",
    "        if idx == 0:\n",
    "            pair = get_pairs_from_bass(midis[idx], midis[idx+1], preds, instrument)\n",
    "        else:\n",
    "            pair = get_pair_with_fixed_first(np.array(pair.midis_b), midis[idx+1], preds, instrument)\n",
    "        if pair is None:\n",
    "            # raise ValueError(f\"At index: {idx} (pitch pair: {(midis[idx], midis[idx+1])})\")\n",
    "            chord_pairs = chord_pairs[:-1]\n",
    "            idx -= 1\n",
    "        chord_pairs.append(pair)\n",
    "\n",
    "    return pl.DataFrame(chord_pairs, schema=voice_leading_schema)\n",
    "\n",
    "\n",
    "def get_progression_from_one_note(note, n, preds, instrument):\n",
    "    chord_pairs = []\n",
    "    idx = 0\n",
    "    while idx < n:\n",
    "        if idx == 0:\n",
    "            pair = get_pairs_from_bass(note, None, preds, instrument)\n",
    "        else:\n",
    "            pair = get_pair_with_fixed_first(np.array(chord_pairs[-1].midis_b), None, preds, instrument)\n",
    "        if pair is None:\n",
    "            print(f\"Back tracking... {idx=}\")\n",
    "            if idx == 0:\n",
    "                print(\"Nothing found...\")\n",
    "                return []\n",
    "            chord_pairs = chord_pairs[:-1]\n",
    "            idx -= 1\n",
    "            continue\n",
    "            \n",
    "        chord_pairs.append(pair)\n",
    "        idx += 1\n",
    "\n",
    "    return pl.DataFrame(chord_pairs, schema=voice_leading_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb490d-53f7-44b8-81d4-02859780b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicates = [\n",
    "    lambda vl: vl.n_pseudo_changes == 0,\n",
    "    # lambda vl: vl.n_common_notes == 7,\n",
    "    lambda vl: vl.n_common_notes <= 5,\n",
    "    lambda vl: vl.max_step_size <= 7,\n",
    "    lambda vl: vl.n_swaps == 0,\n",
    "    lambda vl: vl.motion_balance <= 4/5,\n",
    "    lambda vl: vl.motion_balance >= 1/5,\n",
    "    # lambda vl: vl.n_upward_motion >= 3,\n",
    "    # lambda vl: vl.change_in_span >= 2,\n",
    "    # lambda vl: vl.change_in_span >= 4\n",
    "    # lambda vl: sum(vl.intervals_b) <= sum(vl.intervals_a),\n",
    "    # lambda vl: vl.entropy_of_changes >= 0.9,\n",
    "    lambda vl: vl.midis_b[0] >= vl.midis_a[0]\n",
    "] \n",
    "\n",
    "progression = get_progression_from_one_note(31, 32, predicates, 0)\n",
    "progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204df6b7-5b58-4806-9aa7-6115a496eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = mido.MidiFile()\n",
    "mid.ticks_per_beat = 480\n",
    "tracks = [mido.MidiTrack() for _ in range(12)]\n",
    "for t in tracks:\n",
    "    mid.tracks.append(t)\n",
    "\n",
    "did_name = False\n",
    "for entry in progression.iter_rows(named=True):\n",
    "    if not did_name:\n",
    "        for t, m, i in zip(mid.tracks, entry[\"midis_a\"][::-1], ensemble[::-1]):\n",
    "            t.append(mido.MetaMessage('track_name', name=i.name, time=0))\n",
    "            t.append(mido.Message('program_change', program=i.program, time=0))\n",
    "            did_name = True\n",
    "\n",
    "            t.append(mido.Message('note_on', note=m, velocity=64, time=0))\n",
    "            t.append(mido.Message('note_off', note=m, velocity=127, time=480))\n",
    "    \n",
    "    for t, m, i in zip(mid.tracks, entry[\"midis_b\"][::-1], ensemble[::-1]):\n",
    "        t.append(mido.Message('note_on', note=m, velocity=64, time=0))\n",
    "        t.append(mido.Message('note_off', note=m, velocity=127, time=480))\n",
    "\n",
    "out_dir = Path(ROOT_PATH).joinpath(\"out\")\n",
    "\n",
    "mid.save(out_dir / f'm_{round(time.time())}.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02546c94-df23-4843-8c66-365bcceeac19",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "\n",
    "- [ ] create a Phrase or Passage or Line or something class to store a string of chord motions\n",
    "- [x] put in instrument ranges and track numbers, program change message to set instruments\n",
    "- [ ] generate midi messages into appropriate tracks, some tracks may have multiple voices while others have none\n",
    "- [x] put in a switch to treat bass as octave lower (midi 35 will be converted to midi 23) can also move all the others up an octave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7558205a-fe1f-4522-9798-a27abc9808fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
