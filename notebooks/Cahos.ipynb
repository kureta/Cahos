{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad25a3b2-9b9e-425f-9744-aa93f292fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cahos import Scale, VoiceLeading, get_scales, make_scale, make_voice_leading\n",
    "import polars as pl\n",
    "import mido\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff7ada-de39-4dc0-9df1-1e3f69c1dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_subseq = [\n",
    "    [1, 2], [2, 1], [3, 1],\n",
    "    # [3, 4], [4, 3],\n",
    "    [6, 1], [1, 6], [5, 1], [1, 5],\n",
    "    [1, 1], [2, 2],  # [3, 3], [4, 4],\n",
    "    [5, 5, 5], [6, 6, 6], [7, 7, 7],\n",
    "]\n",
    "\n",
    "# 80 is the maximum span we can get with the Cahos ensemble\n",
    "# Will drop bass by an octave, hence `-12`\n",
    "base_chords = [s for s in get_scales(\n",
    "    allowed_intervals=[1, 2, 3, 4, 5, 6, 7],\n",
    "    disallowed_subsequences=dis_subseq,\n",
    "    disallowed_beginnings=[],\n",
    "    max_span=80-12\n",
    ")]\n",
    "\n",
    "print(f\"number of scales satisfying given constraints: {len(base_chords)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89de07e-ec3e-4294-bfbd-4334a80e1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_chords = pl.DataFrame(base_chords)\n",
    "print(df_base_chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249904e3-2bbd-45f2-b46a-4e297ceb6191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selection = df_base_chords.filter(\n",
    "    pl.col(\"n_unique_intervals\") == 3\n",
    ").sort([\"sequence_entropy\", \"entropy\", \"span\"], descending=True)\n",
    "print(df_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30551040-9e26-4374-9243-99f4cf1b8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shared_notes = 5\n",
    "upper_limit = 108\n",
    "lower_limit = 28\n",
    "min_motion_balance = 3/4\n",
    "max_n_swaps = 0\n",
    "max_step_size = 3\n",
    "n_pseudo_changes = 0\n",
    "\n",
    "b1 = 40\n",
    "b2 = 42\n",
    "\n",
    "voice_leading_opportunities = []\n",
    "for c1 in df_selection.rows():\n",
    "    for c2 in df_selection.rows():\n",
    "        vl = make_voice_leading(c1[0], b1, c2[0], b2)\n",
    "        if max(vl.midis_a + vl.midis_b) > upper_limit or min(vl.midis_a + vl.midis_b) < lower_limit or vl.motion_balance < min_motion_balance or vl.n_swaps > max_n_swaps:\n",
    "            continue\n",
    "        if vl.n_common_notes == n_shared_notes and vl.max_step_size < max_step_size and vl.n_pseudo_changes == n_pseudo_changes:\n",
    "            voice_leading_opportunities.append(vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8347ce4-6b04-4ff4-b58c-fedd64a61bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vl = pl.DataFrame(voice_leading_opportunities)\n",
    "print(df_vl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02546c94-df23-4843-8c66-365bcceeac19",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "\n",
    "- [ ] create a Phrase or Passage or Line or something class to store a string of chord motions\n",
    "- [ ] put in instrument ranges and track numbers, program change message to set instruments\n",
    "- [ ] generate midi messages into appropriate tracks, some tracks may have multiple voices while others have none\n",
    "- [ ] put in a switch to treat bass as octave lower (midi 35 will be converted to midi 23) can also move all the others up an octave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26565d-14f4-4d73-b9bd-621668bc8db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Instrument:\n",
    "    name: str\n",
    "    program: int\n",
    "    register: Tuple[int, int]\n",
    "\n",
    "piccolo = Instrument(\"Piccolo\", 72, (74, 102))\n",
    "flute = Instrument(\"Flute\", 73, (60, 96))\n",
    "oboe = Instrument(\"Oboe\", 68, (58, 91))\n",
    "clarinet = Instrument(\"Clarinet\", 71, (50, 94))\n",
    "bass_clarinet = Instrument(\"Bass Clarinet\", 71, (38, 77))\n",
    "horn = Instrument(\"Horn\", 59, (34, 77))\n",
    "trombone = Instrument(\"Trombone\", 59, (40, 72))\n",
    "violin = Instrument(\"Violin\", 44, (55, 103))\n",
    "viola = Instrument(\"Viola\", 44, (48, 91))\n",
    "cello = Instrument(\"Violoncello\", 44, (36, 76))\n",
    "contrabass = Instrument(\"Contrabass\", 44, (28, 67))\n",
    "\n",
    "ensemble = [piccolo, violin, flute, violin, oboe, viola, clarinet, bass_clarinet, horn, trombone, cello, contrabass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9334c400-ae1a-4b22-8f54-57fe279297ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = mido.MidiFile()\n",
    "mid.ticks_per_beat = 480\n",
    "tracks = [mido.MidiTrack() for _ in range(12)]\n",
    "for t in tracks:\n",
    "    mid.tracks.append(t)\n",
    "\n",
    "midis_a = list(df_vl[0][\"midis_a\"][0][::-1])\n",
    "midis_b = list(df_vl[0][\"midis_b\"][0][::-1])\n",
    "for t, m, i in zip(mid.tracks, midis_a, ensemble):\n",
    "    while m < i.register[0]:\n",
    "        m += 12\n",
    "        print(f\"raised octave for {i.name}\")\n",
    "    while m > i.register[1]:\n",
    "        m -= 12\n",
    "        print(f\"lowered octave for {i.name}\")\n",
    "    t.append(mido.MetaMessage('track_name', name=i.name, time=0))\n",
    "    t.append(mido.Message('program_change', program=i.program, time=0))\n",
    "    t.append(mido.Message('note_on', note=m, velocity=64, time=0))\n",
    "    t.append(mido.Message('note_off', note=m, velocity=127, time=480*4))\n",
    "for t, m in zip(mid.tracks, midis_b):\n",
    "    t.append(mido.Message('note_on', note=m, velocity=64, time=0))\n",
    "    t.append(mido.Message('note_off', note=m, velocity=127, time=480*4))\n",
    "\n",
    "mid.save('/home/kureta/Downloads/new_song.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca1f7bc-092c-442e-ae42-5954f1920391",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = {}\n",
    "for t in mid.tracks:\n",
    "    current_name = \"\"\n",
    "    for m in t:\n",
    "        if m.is_meta and m.type == 'track_name':\n",
    "            current_name = m.name\n",
    "        elif m.type == 'program_change':\n",
    "            instruments[current_name] = m.program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1163a-e961-4d62-9149-1af903e173b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = mido.MidiFile(\"/home/kureta/Downloads/Untitled score.mid\")\n",
    "mid.print_tracks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645637df-9c74-4cec-826c-849897e75114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
