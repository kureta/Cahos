{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9655212c-7be5-4b63-9c5c-c108ffee32e3",
   "metadata": {},
   "source": [
    "# Omni Chords - for Cahos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d224e-e630-4a02-ba52-c040595c470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import accumulate\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0faec8-6b80-4dea-8510-5145f79db102",
   "metadata": {},
   "source": [
    "## Generate Omni-Chords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95807d2-d2a2-48b3-8ad8-8bdeb5fc3951",
   "metadata": {},
   "source": [
    "### Entropy calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c2900-1d47-4863-8ecc-49d1c6ff9e85",
   "metadata": {},
   "source": [
    "Using Shannon entropy. Also using \"sub-sequence entropy\" and \"sequence entropy\":\n",
    "For \"sub-sequence entropy\" we take length n sub sequences of a list and treat them as symbols,\n",
    "and calculate the entropy of that. Sequence entropy is just the sum of sub-sequence entropies of all lengths\n",
    "\n",
    "```python\n",
    "sequence = [2, 1, 2, 2, 1]\n",
    "entropy = calculate_entropy(sequence)\n",
    "# 2-length sub-sequence entropy:\n",
    "subseq_entropy = calculate_entropy([(2, 1), (1, 2), (2, 2), (2, 1)])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b053287-2035-43c9-a663-6e19676bedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(sequence):\n",
    "    # Count the frequency of each element in the sequence\n",
    "    frequency = Counter(sequence)\n",
    "    total_count = len(sequence)\n",
    "\n",
    "    # Calculate the entropy\n",
    "    entropy = 0\n",
    "    for count in frequency.values():\n",
    "        probability = count / total_count\n",
    "        entropy -= probability * log2(probability)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def calculate_subseq_entropy(sequence, subsequence_length):\n",
    "    sub_seqs = []\n",
    "    for idx in range(len(sequence)-subsequence_length+1):\n",
    "        sub_seqs.append(tuple(sequence[idx:idx+subsequence_length]))\n",
    "    return calculate_entropy(sub_seqs)\n",
    "\n",
    "def calculate_sequence_entropy(sequence):\n",
    "    return sum(calculate_subseq_entropy(sequence, l) for l in range(len(sequence)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1559af9-46b9-4300-a335-c264653b4e03",
   "metadata": {},
   "source": [
    "The Scale (more aptly chord) has a few properties of interest:\n",
    "\n",
    "- `sequence_entropy`\n",
    "- `span`: distance between the lowest and the highest note in chord\n",
    "- `inervals`: all interval types contained in the chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f92954-2e3f-4c95-8b29-a0fb58f2b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scale:\n",
    "    def __init__(self, deltas):\n",
    "        self.deltas = deltas\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.deltas}\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"entropy: {self.sequence_entropy:.2f}, span: {self.span}, deltas: {self.deltas}\"\n",
    "\n",
    "    @property\n",
    "    def pitch_classes(self):\n",
    "        return [a % 12 for a in accumulate(self.deltas, initial=0)]\n",
    "\n",
    "    def transposed(self, start=0):\n",
    "        return [a % 12 for a in accumulate(self.deltas, initial=start)]\n",
    "\n",
    "    def realization(self, start=0):\n",
    "        return [a for a in accumulate(self.deltas, initial=start)]\n",
    "\n",
    "    @property\n",
    "    def span(self):\n",
    "        return sum(self.deltas)\n",
    "\n",
    "    @property\n",
    "    def intervals(self):\n",
    "        return list(set(self.deltas))\n",
    "\n",
    "    @property\n",
    "    def n_intervals(self):\n",
    "        return len(set(self.deltas))\n",
    "\n",
    "    @property\n",
    "    def entropy(self):\n",
    "        return calculate_entropy(self.deltas)\n",
    "\n",
    "    @property\n",
    "    def transition_entropy(self):\n",
    "        return calculate_subseq_entropy(self.deltas, 2)\n",
    "\n",
    "    @property\n",
    "    def sequence_entropy(self):\n",
    "        return calculate_sequence_entropy(self.deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3954d713-6ec3-471c-aa8c-c2b0e24cc603",
   "metadata": {},
   "source": [
    "### Generating omni-chords subject to some constraints\n",
    "\n",
    "There are *a lot* of possible omni-chords. So, some constraints are applied during generation\n",
    "to enable early termination of the search.\n",
    "\n",
    "- `allowed_intervals`: List of intervals that an omni-chord can contain\n",
    "- `disallowed_subsequences`: Mostly to exclude chromatic clusters. No consequtive minor deconds, etc.\n",
    "- `disallowed_beginnings`: Usually don't want narrow intervals between the bass and the next note.\n",
    "- `max_span`: Maximum distance between the lowest and higihest note for an interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a129cd-9c84-40c3-b4ff-303e5c7641a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_subsequence(main_list, sub_list):\n",
    "    for idx in range(len(main_list) - len(sub_list) + 1):\n",
    "        if main_list[idx: idx + len(sub_list)] == sub_list:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_scales(allowed_intervals, disallowed_subsequences=[], disallowed_beginnings=[], max_span=88):\n",
    "    result = []\n",
    "    get_scales_recursive(allowed_intervals, disallowed_subsequences, disallowed_beginnings, max_span, result)\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_scales_recursive(allowed_intervals, disallowed_subsequences, disallowed_beginnings, max_span, deltas_accumulator,\n",
    "                         pitch_classes=[0], deltas=[], idx=0):\n",
    "    if idx == 11:\n",
    "        deltas_accumulator.append(deltas)\n",
    "        # normal exit\n",
    "        return\n",
    "    for next_interval in allowed_intervals:\n",
    "        # early exits\n",
    "        if (idx == 0) and (next_interval in disallowed_beginnings):\n",
    "            continue\n",
    "        if sum(deltas + [next_interval]) > max_span:\n",
    "            continue\n",
    "        if any(contains_subsequence(deltas + [next_interval], dis_seq) for dis_seq in disallowed_subsequences):\n",
    "            continue\n",
    "        next_note = (pitch_classes[-1] + next_interval) % 12\n",
    "        if next_note not in pitch_classes:\n",
    "            get_scales_recursive(allowed_intervals, disallowed_subsequences, disallowed_beginnings, max_span, deltas_accumulator,\n",
    "                      pitch_classes + [next_note], deltas + [next_interval], idx + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e40c7-8fda-48a9-9718-2addb5cef2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_subseq = [\n",
    "    [1, 2], [2, 1], [3, 1],\n",
    "    [3, 4], [4, 3],\n",
    "    [6, 1], [1, 6], [5, 1], [1, 5],\n",
    "    [1, 1], [2, 2],  # [3, 3], [4, 4],\n",
    "    [5, 5, 5], [6, 6, 6], [7, 7, 7],\n",
    "]\n",
    "\n",
    "# 80 is the maximum span we can get with the Cahos ensemble\n",
    "scales = [Scale(s) for s in get_scales(\n",
    "    allowed_intervals=[1, 2, 3, 4, 5, 6, 7],\n",
    "    disallowed_subsequences=dis_subseq,\n",
    "    disallowed_beginnings=[],\n",
    "    max_span=80-12\n",
    ")]\n",
    "\n",
    "print(f\"number of scales satisfying given constraints: {len(scales)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1d0f9-7897-4ce1-9d3f-4e71d002e8c0",
   "metadata": {},
   "source": [
    "### Further filtering and sorting\n",
    "\n",
    "Can filter and/or sort by exact number of intervals, entropy, sequence entropy, span..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef14f58-2097-4d8b-99a9-11770aa6e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intervals = 3\n",
    "selection = sorted([s for s in scales if s.n_intervals == n_intervals], key=lambda x: (x.sequence_entropy, x.span), reverse=True)\n",
    "show_n = 5\n",
    "print(f\"first {min(show_n, len(selection))} of {len(selection)} scales remaining after filtering\")\n",
    "for s in selection[:show_n]:\n",
    "    print(s)\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f92d2-06b5-4aaf-82bf-8bdbc1f804f1",
   "metadata": {},
   "source": [
    "### Voice leading opportunities\n",
    "\n",
    "- Number of shared notes between two chords.\n",
    "- Number of simple swaps among moving notes (ex. 1 -> 0 and 0 -> 1)\n",
    "- Bass motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d9598-1246-42dd-8024-6840a527c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_swaps(xs, ys):\n",
    "    none_matches = [(a, b) for a, b in zip (xs, ys) if a != b]\n",
    "    swaps = []\n",
    "    for item in none_matches:\n",
    "        if tuple(item[::-1]) in none_matches:\n",
    "            swaps.append(item)\n",
    "    \n",
    "    return len(swaps)\n",
    "\n",
    "def mark_changes(first, second):\n",
    "    return [int(a != b) for a, b in zip(first, second)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8011aab-4ba0-4e34-aa9f-3fec61a204a2",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Create a `VoiceLeading` class that will contain and calculate voice leading information such as:\n",
    "\n",
    "- a binary array showing changed voices\n",
    "- sequence entropy of changes indicated by that array\n",
    "- list of common notes\n",
    "- list of changed notes\n",
    "- numbers of common notes, changed notes, swaps\n",
    "- change in span\n",
    "- chord a and chord b\n",
    "- numbers of up/down motions (to find voice leadings with more contrary motion)\n",
    "- detect voice crossings (not corssings but ex. a b c going to b c d)\n",
    "    - a changed note (not pitch class) shouldn't be in the previous chord.\n",
    "- max jump distance of changing voices\n",
    "\n",
    "Also define a `get_voice_leading(chord_a, `list_of_chords`, n_shared_notes, min_bass_distance=0) -> List[VoiceLeading]` function. list_of_chords doesn't have to be from the same family as `chord_a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6fd36c-b177-4bd3-9b2d-f17b7e42d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "\n",
    "def midi_to_note_name(midi_number):\n",
    "    octave = (midi_number // 12) - 1\n",
    "    note_index = midi_number % 12\n",
    "    return f\"{note_names[note_index]}{octave}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10c9c0-b52a-4fc4-aaa4-5ac227f57c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceLeading:\n",
    "    def __init__(self, chord_a: Scale, base_a: int, chord_b: Scale, base_b: int):\n",
    "        self.chord_a = chord_a\n",
    "        self.base_a = base_a\n",
    "        self.chord_b = chord_b\n",
    "        self.base_b = base_b\n",
    "\n",
    "    @property\n",
    "    def real_a(self):\n",
    "        return self.chord_a.realization(self.base_a)\n",
    "\n",
    "    @property\n",
    "    def real_b(self):\n",
    "        return self.chord_b.realization(self.base_b)\n",
    "\n",
    "    @property\n",
    "    def real_a_names(self):\n",
    "        return [midi_to_note_name(x) for x in self.chord_a.realization(self.base_a)]\n",
    "\n",
    "    @property\n",
    "    def real_b_names(self):\n",
    "         return [midi_to_note_name(x) for x in self.chord_b.realization(self.base_b)]\n",
    "    \n",
    "    def onehot_changed_voices(self):\n",
    "        return [int(a != b) for a, b in zip(self.real_a, self.real_b)]\n",
    "\n",
    "    def sequence_entropy_of_changes(self):\n",
    "        return calculate_sequence_entropy(self.onehot_changed_voices())\n",
    "\n",
    "    def common_notes(self):\n",
    "        return [a for a, b in zip(self.real_a, self.real_b) if a == b]\n",
    "\n",
    "    def changed_notes(self):\n",
    "        return [(a, b) for a, b in zip(self.real_a, self.real_b) if a != b]\n",
    "\n",
    "    def swaps(self):\n",
    "        none_matches = [(a, b) for a, b in zip (self.real_a, self.real_b) if a != b]\n",
    "        swaps = []\n",
    "        for item in none_matches:\n",
    "            if tuple(item[::-1]) in none_matches:\n",
    "                swaps.append(item)\n",
    "        \n",
    "        return swaps\n",
    "\n",
    "    def n_common_notes(self):\n",
    "        return len(self.common_notes())\n",
    "\n",
    "    def n_changed_notes(self):\n",
    "        return len(self.changed_notes())\n",
    "\n",
    "    def n_swaps(self):\n",
    "        return len(self.swaps())\n",
    "\n",
    "    def change_in_span(self):\n",
    "        return self.chord_b.span - self.chord_a.span\n",
    "\n",
    "    def n_upward_motion(self):\n",
    "        n = 0\n",
    "        for a, b in self.changed_notes():\n",
    "            if b > a: n += 1\n",
    "        return n\n",
    "\n",
    "    def n_downward_motion(self):\n",
    "        n = 0\n",
    "        for a, b in self.changed_notes():\n",
    "            if a > b: n += 1\n",
    "        return n\n",
    "\n",
    "    def motion_balance(self):\n",
    "        if self.n_downward_motion() == 0: return 0.0\n",
    "        ratio = self.n_upward_motion() / self.n_downward_motion()\n",
    "        if ratio > 1.0: ratio = 1 / ratio\n",
    "        return ratio\n",
    "\n",
    "    def max_step_size(self):\n",
    "        return max([abs(a-b) for a, b in self.changed_notes()])\n",
    "\n",
    "    def n_pseudo_changes(self):\n",
    "        n = 0\n",
    "        for a, b in self.changed_notes():\n",
    "            if b in self.real_a:\n",
    "                n += 1\n",
    "        return n\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"seq entropy: {self.chord_a.sequence_entropy:.2f} span: {self.chord_a.span} | {self.real_a_names}\\n\" \\\n",
    "               f\"seq entropy: {self.chord_b.sequence_entropy:.2f} span: {self.chord_b.span} | {self.real_b_names}\\n\" \\\n",
    "               f\"{self.n_common_notes()} common | {self.n_changed_notes()} changes | {self.n_swaps()} swaps\\n\" \\\n",
    "               f\"changed places: {self.onehot_changed_voices()}\\n\" \\\n",
    "               f\"sequence entropy of changes: {self.sequence_entropy_of_changes():.2f}\\n\" \\\n",
    "               f\"max step size: {self.max_step_size()}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c8465-33da-4eba-8126-9c5f827c445b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_bass_distance = 2\n",
    "n_shared_notes = 5\n",
    "\n",
    "for ss in selection:\n",
    "    for st in selection:\n",
    "        for i in range(12):\n",
    "            shifted = [(pc + i) % 12 for pc in st.pitch_classes]\n",
    "            matches = [a for a, b in zip(ss.pitch_classes, shifted) if a == b]\n",
    "            d1 = (shifted[0] - ss.pitch_classes[0]) % 12\n",
    "            d2 = (ss.pitch_classes[0] - shifted[0]) % 12\n",
    "            if (len(matches) == n_shared_notes) and (d1 > min_bass_distance) and (d2 > min_bass_distance):\n",
    "                print(f\"span: {ss.span}\", ss.pitch_classes)\n",
    "                print(f\"span: {st.span}\", shifted)\n",
    "                print(f\"common voices: {matches}\")\n",
    "                print(f\"{len(matches)} common | {12 - len(matches)} changes | {n_swaps(shifted, ss.pitch_classes)} swaps\")\n",
    "                print(f\"marked changes: {mark_changes(ss.pitch_classes, shifted)}\")\n",
    "                print(f\"sequence entropy of changes: {calculate_sequence_entropy(mark_changes(ss.pitch_classes, shifted)):.2f}\")\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3e00f-f1b4-4ba1-b6f4-9c4197816534",
   "metadata": {},
   "source": [
    "## Generate Composition Material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73cd73-fdcb-4193-bd10-c9cde25028a1",
   "metadata": {},
   "source": [
    "### Epigraph\n",
    "\n",
    "- Nothing changes because everything is already there (The history, empires, art, architecture, cradle of civilizations).\n",
    "- Everything changes because chaos is the fountain from which cosmos emerges (Yet still creative, leading, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098db77-e24b-4c6c-97be-49763c1ed5d3",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Some properties of interest are:\n",
    "\n",
    "scale:\n",
    "\n",
    "- span\n",
    "- sequence entropy\n",
    "- number of intervals / allowed intervals\n",
    "\n",
    "voice leading:\n",
    "\n",
    "- sequence entropy of changes\n",
    "- list of common notes\n",
    "- list of tuples of changed notes\n",
    "- numbers of common notes, changed notes, swaps\n",
    "- change in span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e715f7cb-044c-4d78-b9c4-568615f6eb49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_shared_notes = 4\n",
    "\n",
    "b1 = 43\n",
    "b2 = 40\n",
    "voice_leading_opportunities = []\n",
    "for ss in selection:\n",
    "    for st in selection:\n",
    "        shifted = st.realization(b2)\n",
    "        matches = [a for a, b in zip(ss.realization(b1), shifted) if a == b]\n",
    "        if shifted[-1] > 108 or ss.realization(b1)[-1] > 108:\n",
    "            continue\n",
    "        if (len(matches) == n_shared_notes) and ((st.span - ss.span) >= 12):  # and (calculate_sequence_entropy(mark_changes(ss.realization(b1), shifted)) > 24.11):\n",
    "            voice_leading_opportunities.append(VoiceLeading(ss, b1, st, b2))\n",
    "            print(f\"span: {ss.span}\", [midi_to_note_name(x) for x in ss.realization(b1)])\n",
    "            print(f\"span: {st.span}\", [midi_to_note_name(x) for x in shifted])\n",
    "            print(f\"common voices: {[midi_to_note_name(x) for x in matches]}\")\n",
    "            print(f\"{len(matches)} common | {12 - len(matches)} changes | {n_swaps(shifted, ss.realization(b1))} swaps\")\n",
    "            print(f\"marked changes: {mark_changes(ss.realization(b1), shifted)}\")\n",
    "            print(f\"sequence entropy of changes: {calculate_sequence_entropy(mark_changes(ss.realization(b1), shifted)):.2f}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4142d653-fc36-4ad8-9fbc-1d82d40d9781",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(voice_leading_opportunities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a92854-025f-4580-897b-61f629628fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shared_notes = 4\n",
    "\n",
    "b1 = 43\n",
    "b2 = 40\n",
    "voice_leading_opportunities = []\n",
    "for c1 in selection:\n",
    "    for c2 in selection:\n",
    "        vl = VoiceLeading(c1, b1, c2, b2)\n",
    "        if vl.real_a[-1] > 108 or vl.real_b[-1] > 108 or vl.real_a[0] < 28 or vl.real_b[0] < 28 or vl.motion_balance() < 3/4 or vl.n_swaps() > 0:\n",
    "            continue\n",
    "        if vl.n_common_notes() == n_shared_notes and vl.change_in_span() >= 12 and vl.n_pseudo_changes() == 0:\n",
    "            voice_leading_opportunities.append(vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e188c0f-6934-4659-8f33-7d74ff5bd751",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vl in sorted(voice_leading_opportunities, key=lambda x: (-x.sequence_entropy_of_changes(), x.n_swaps())):\n",
    "    print(f\"{vl.chord_a.sequence_entropy:.2f}\", vl.real_a_names, f\"{vl.chord_b.sequence_entropy:.2f}\", vl.real_b_names, f\"{vl.sequence_entropy_of_changes():.2f}\", vl.n_swaps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bce573-0d5a-49cb-bed3-d9cf9a01e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shared_notes = 5\n",
    "\n",
    "b1 = 40\n",
    "b2 = 42\n",
    "voice_leading_opportunities = []\n",
    "for c1 in selection:\n",
    "    for c2 in selection:\n",
    "        vl = VoiceLeading(c1, b1, c2, b2)\n",
    "        if max(vl.real_a + vl.real_b) > 108 or min(vl.real_a + vl.real_b) < 28 or vl.motion_balance() < 3/4 or vl.n_swaps() > 0:\n",
    "            continue\n",
    "        if vl.n_common_notes() == n_shared_notes and vl.max_step_size() < 3 and vl.n_pseudo_changes() == 0:\n",
    "            voice_leading_opportunities.append(vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bda53b-6a81-440b-9864-e1522cd71075",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vl in sorted(voice_leading_opportunities, key=lambda x: (x.change_in_span(), -x.sequence_entropy_of_changes())):\n",
    "    print(vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8382c90-6808-419d-9ae2-dbf78f3fabda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
